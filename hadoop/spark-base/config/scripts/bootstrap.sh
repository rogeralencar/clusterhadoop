#!/bin/bash

# Este trecho rodar치 independente de termos um container master ou
# worker. Neces치rio para funcionamento do HDFS e para comunica칞칚o
# dos containers/nodes.
/etc/init.d/ssh start

# Abaixo temos o trecho que rodar치 apenas no master.
if [[ $HOSTNAME = spark-master ]]; then
    
    # Formatamos o namenode
    hdfs namenode -format

    # Iniciamos os servi칞os
    $HADOOP_HOME/sbin/start-dfs.sh
    $HADOOP_HOME/sbin/start-yarn.sh

    # Cria칞칚o de diret칩rios no ambiente distribu칤do do HDFS
    hdfs dfs -mkdir /spark_logs
    hdfs dfs -mkdir /datasets
    hdfs dfs -mkdir /datasets_processed
    hdfs dfs -mkdir /lab08

    # Envia os arquivos da pasta user_data para o HDFS
   
    hdfs dfs -put /user_data/lab08/* /lab08 
   
    # Caso mantenha notebooks personalizados na pasta que tem bind mount com o 
    # container /user_data, o trecho abaixo automaticamente far치 o processo de 
    # confiar em todos os notebooks, tamb칠m liberando o server do jupyter de
    # solicitar um token
    cd /user_data
    jupyter trust *.ipynb
    jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password='' &

    # Inicializa o servi每 do FastAPI
    uvicorn api:app --host 0.0.0.0 --port 8000 --reload

    while ! hdfs dfs -test -d /datasets;
    do
        echo "datasets doesn't exist yet... retrying"
        sleep 1;
    done

    while ! hdfs dfs -mkdir -p /spark_logs;
    do
        echo "Failed creating /spark_logs hdfs dir"
        sleep 1;
    done

# E abaixo temos o trecho que rodar치 nos workers
else

    # Configs de HDFS nos dataNodes (workers)
    $HADOOP_HOME/sbin/hadoop-daemon.sh start datanode &
    $HADOOP_HOME/bin/yarn nodemanager &
    
fi

while :; do sleep 2073600; done
